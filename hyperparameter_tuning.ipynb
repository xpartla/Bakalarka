{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:52:23.250286Z",
     "start_time": "2025-04-21T10:52:20.500397400Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.max_columns = None\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will apply the preprocessing steps and continue with tuning of the models, using the best performing feature selection method we found in the preprocessing notebook."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f69c095165d9b2"
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/data.csv', low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:52:25.759095400Z",
     "start_time": "2025-04-21T10:52:23.235184800Z"
    }
   },
   "id": "f396314cfb41a86b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "max_vals = df.select_dtypes(include='number').max()\n",
    "max_9 = max_vals[max_vals == 9].index.tolist()\n",
    "for col in max_9:\n",
    "    df.loc[df[col] == 9, col] = np.nan \n",
    "max_vals = df.select_dtypes(include='number').max()\n",
    "max_8 = max_vals[max_vals == 8].index.tolist()\n",
    "\n",
    "missing_subset = {'ALCFREQ', 'HATTMULT', 'STROKMUL', 'TIAMULT', 'ARTHTYPE', 'ARTHUPEX', 'ARTHLOEX', 'ARTHSPIN', 'ARTHUNK', 'CVDCOG', 'STROKCOG', 'CVDIMAG', 'CVDIMAG1', 'CVDIMAG2', 'CVDIMAG3', 'CVDIMAG4', 'PDNORMAL', 'SPEECH', 'FACEXP', 'TRESTRHD', 'TRESTLHD', 'TRESTRFT', 'TRESTLFT', 'TRACTRHD', 'TRACTLHD', 'RIGDNECK', 'RIGDUPRT', 'RIGDUPLF', 'RIGDLORT', 'RIGDLOLF', 'TAPSRT', 'TAPSLF', 'HANDMOVR', 'HANDMOVL', 'HANDALTR', 'HANDALTL', 'LEGRT', 'LEGLF', 'ARISING', 'POSTURE', 'GAIT', 'POSSTAB', 'BRADYKIN', 'RESTTRL', 'RESTTRR', 'SLOWINGL', 'SLOWINGR', 'RIGIDL', 'RIGIDR', 'BRADY', 'POSTINST', 'CORTDEF', 'SIVDFIND', 'CVDMOTL', 'CVDMOTR', 'CORTVISL', 'CORTVISR', 'SOMATL', 'SOMATR', 'EYEPSP', 'DYSPSP', 'AXIALPSP', 'GAITPSP', 'APRAXSP', 'APRAXL', 'APRAXR', 'CORTSENL', 'CORTSENR', 'ATAXL', 'ATAXR', 'ALIENLML', 'ALIENLMR', 'DYSTONL', 'DYSTONR', 'MYOCLLT', 'MYOCLRT', 'MOMOPARK', 'MOMOALS', 'AMNDEM', 'PCA', 'NAMNDEM', 'AMYLPET', 'AMYLCSF', 'FDGAD', 'HIPPATR', 'TAUPETAD', 'CSFTAU', 'FDGFTLD', 'TPETFTLD', 'MRFTLD', 'DATSCAN', 'IMAGLINF', 'IMAGLAC', 'IMAGMACH', 'IMAGMICH', 'IMAGMWMH', 'IMAGEWMH', 'CANCER', 'MYOINF', 'CONGHRT', 'AFIBRILL', 'HYPERT', 'ANGINA', 'HYPCHOL', 'VB12DEF', 'THYDIS', 'ARTH', 'ARTYPE', 'ARTUPEX', 'ARTLOEX', 'ARTSPIN', 'ARTUNKN', 'URINEINC', 'BOWLINC', 'SLEEPAP', 'REMDIS', 'HYPOSOM', 'SLEEPOTH', 'ANGIOCP', 'ANGIOPCI', 'PACEMAKE', 'HVALVE', 'ANTIENC'}\n",
    "cols_to_change = list(missing_subset.intersection(max_8))\n",
    "df[cols_to_change] = df[cols_to_change].replace(8, np.nan)\n",
    "max_vals = df.select_dtypes(include='number').max()\n",
    "max_8 = max_vals[max_vals == 8].index.tolist()\n",
    "\n",
    "df = df.drop(columns=['NPWBRF', 'NACCBRNN', 'NPGRCCA', 'NPGRLA', 'NPGRHA', 'NPGRSNH', 'NPGRLCH', 'NACCAVAS', 'NPTAN', 'NPABAN', 'NPASAN', 'NPTDPAN', 'NPTHAL', 'NACCBRAA', 'NACCNEUR', 'NPADNC', 'NACCDIFF', 'NACCAMY', 'NPINF', 'NACCINF', 'NPHEMO', 'NPHEMO1', 'NPHEMO2', 'NPHEMO3', 'NPOLD', 'NPOLD1', 'NPOLD2', 'NPOLD3', 'NPOLD4', 'NACCMICR', 'NPOLDD', 'NPOLDD1', 'NPOLDD2', 'NPOLDD3', 'NPOLDD4', 'NACCHEM', 'NACCARTE', 'NPWMR', 'NPPATH', 'NACCNEC', 'NPPATH2', 'NPPATH3', 'NPPATH4', 'NPPATH5', 'NPPATH6', 'NPPATH7', 'NPPATH8', 'NPPATH9', 'NPPATH10', 'NPPATH11', 'NACCLEWY', 'NPLBOD', 'NPNLOSS', 'NPHIPSCL', 'NPFTDTAU', 'NACCPICK', 'NPFTDT2', 'NACCCBD', 'NACCPROG', 'NPFTDT5', 'NPFTDT6', 'NPFTDT7', 'NPFTDT8', 'NPFTDT9', 'NPFTDT10', 'NPFTDTDP', 'NPALSMND', 'NPOFTD', 'NPOFTD1', 'NPOFTD2', 'NPOFTD3', 'NPOFTD4', 'NPOFTD5', 'NPTDPA', 'NPTDPB', 'NPTDPC', 'NPTDPD', 'NPTDPE', 'NPPDXA', 'NPPDXB', 'NACCPRIO', 'NPPDXD', 'NPPDXE', 'NPPDXF', 'NPPDXG', 'NPPDXH', 'NPPDXI', 'NPPDXJ', 'NPPDXK', 'NPPDXL', 'NPPDXM', 'NPPDXN', 'NPPDXP', 'NPPDXQ', 'NPARTAG', 'NPATGSEV', 'NPATGAMY', 'NPATGAM1', 'NPATGAM2', 'NPATGAM3', 'NPATGAM4', 'NPATGAM5', 'NPATGFRN', 'NPATGFR1', 'NPATGFR2', 'NPATGFR3', 'NPATGFR4'])\n",
    "\n",
    "initial = df.shape[1]\n",
    "threshold = 0.8 * len(df)\n",
    "df = df.dropna(thresh=threshold, axis=1)\n",
    "remaining = df.shape[1]\n",
    "dropped = initial - remaining\n",
    "\n",
    "print(f\"initial: {initial}\")\n",
    "print(f\"remaining: {remaining}\")\n",
    "print(f\"dropped: {dropped}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:52:27.084270200Z",
     "start_time": "2025-04-21T10:52:25.744660200Z"
    }
   },
   "id": "f002baf63680c05d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial: 862\n",
      "remaining: 213\n",
      "dropped: 649\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "impairment_vars = ['BILLS', 'SHOPPING', 'STOVE', 'TRAVEL']\n",
    "\n",
    "functional_impairment = df[impairment_vars].sum(axis=1, skipna=True)\n",
    "\n",
    "df = pd.concat([df, functional_impairment.rename('FUNCTIONAL_IMPAIRMENT')], axis=1)\n",
    "df.drop(columns=impairment_vars, inplace=True)\n",
    "\n",
    "df = df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:52:27.208334800Z",
     "start_time": "2025-04-21T10:52:27.086271100Z"
    }
   },
   "id": "f38e10ce3d63b2a1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "print(df.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:52:27.222997300Z",
     "start_time": "2025-04-21T10:52:27.209336200Z"
    }
   },
   "id": "41e80eb248835ed8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29673\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "conditions = [\n",
    "    (df[\"TIME\"] < 4) & (df[\"OUTCOME_EVENTMCI\"] == False),\n",
    "    (df[\"TIME\"] < 4) & (df[\"OUTCOME_EVENTMCI\"] == True),\n",
    "    (df[\"TIME\"] >= 4) & (df[\"OUTCOME_EVENTMCI\"] == False),\n",
    "    (df[\"TIME\"] >= 4) & (df[\"OUTCOME_EVENTMCI\"] == True)\n",
    "]\n",
    "values = [np.nan, True, False, False]\n",
    "\n",
    "df[\"OUTCOME_WITHIN_4_YEARS\"] = np.select(conditions, values, default=np.nan)\n",
    "df = df.dropna(subset=[\"OUTCOME_WITHIN_4_YEARS\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:52:27.267858Z",
     "start_time": "2025-04-21T10:52:27.226998700Z"
    }
   },
   "id": "4dd05905330df585",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "print(df.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:52:27.281240900Z",
     "start_time": "2025-04-21T10:52:27.257162700Z"
    }
   },
   "id": "1123e75231006779",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18886\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "df = df.drop(columns=['TIME', 'OUTCOME_EVENTMCI'])\n",
    "X = df.drop(columns=['OUTCOME_WITHIN_4_YEARS'])\n",
    "y = df['OUTCOME_WITHIN_4_YEARS']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:52:27.360412200Z",
     "start_time": "2025-04-21T10:52:27.286356Z"
    }
   },
   "id": "fb648bacc3a7cee7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "class HandleOutliers(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower_quantile=0.3, upper_quantile=0.7):\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        self.quantile_bounds_ = {}\n",
    "        numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "        \n",
    "        for col in numeric_columns:\n",
    "            Q1 = X[col].quantile(self.lower_quantile)\n",
    "            Q2 = X[col].quantile(self.upper_quantile)\n",
    "            IQR = Q2 - Q1\n",
    "            self.quantile_bounds_[col] = {\n",
    "                'lower_bound': Q1 - 1.5 * IQR,\n",
    "                'upper_bound': Q2 + 1.5 * IQR\n",
    "            }\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "        for col in numeric_columns:\n",
    "            if col not in self.quantile_bounds_:\n",
    "                continue  \n",
    "            bounds = self.quantile_bounds_[col]\n",
    "            mean_value = X[col].mean()\n",
    "            \n",
    "            X[col] = np.where(X[col] < bounds['lower_bound'], mean_value, \n",
    "                              np.where(X[col] > bounds['upper_bound'], mean_value, X[col]))\n",
    "        return X.values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T10:52:27.369531400Z",
     "start_time": "2025-04-21T10:52:27.333550200Z"
    }
   },
   "id": "187b11c0f74215cf",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic regression tuning:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a30be0f4473bb09"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Logistic Regression Best Parameters: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Best roc_auc score: 0.9464137026210194\n"
     ]
    }
   ],
   "source": [
    "num_cols = X.select_dtypes(['number']).columns\n",
    "cat_cols = X.select_dtypes(['object']).columns\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('outlier', HandleOutliers(lower_quantile=0.3, upper_quantile=0.7)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.1)\n",
    "select_k = SelectKBest(score_func=mutual_info_classif, k=100)\n",
    "log_reg = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "rfe = RFE(estimator=log_reg, n_features_to_select=50)\n",
    "\n",
    "\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('variance_threshold', var_thresh),\n",
    "    ('select_k_best', select_k),\n",
    "    ('rfe', rfe),\n",
    "    ('classifier', LogisticRegression(max_iter=200))\n",
    "])\n",
    "\n",
    "param_grid_lr = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=logreg_pipeline,\n",
    "    param_grid=param_grid_lr,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "print(\"Logistic Regression Best Parameters:\", grid_search_lr.best_params_)\n",
    "print(\"Best roc_auc score:\", grid_search_lr.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-16T13:16:32.323425100Z",
     "start_time": "2025-04-16T13:08:28.485083Z"
    }
   },
   "id": "6dbef8fbda6f83a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM tuning:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec8d5db5d1827c8a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "SVM Best Parameters: {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}\n",
      "Best roc_auc score: 0.9489147447044778\n"
     ]
    }
   ],
   "source": [
    "num_cols = X.select_dtypes(['number']).columns\n",
    "cat_cols = X.select_dtypes(['object']).columns\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('outlier', HandleOutliers(lower_quantile=0.3, upper_quantile=0.7)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.1)\n",
    "select_k = SelectKBest(score_func=mutual_info_classif, k=100)\n",
    "log_reg = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "rfe = RFE(estimator=log_reg, n_features_to_select=50)\n",
    "\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('variance_threshold', var_thresh),\n",
    "    ('select_k_best', select_k),\n",
    "    ('rfe', rfe),\n",
    "    ('classifier', SVC(probability=True))\n",
    "])\n",
    "\n",
    "param_grid_svm = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],  \n",
    "    'classifier__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  \n",
    "    'classifier__gamma': ['scale', 'auto']  \n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=svm_pipeline,\n",
    "    param_grid=param_grid_svm,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "print(\"SVM Best Parameters:\", grid_search_svm.best_params_)\n",
    "print(\"Best roc_auc score:\", grid_search_svm.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T12:21:23.960623900Z",
     "start_time": "2025-04-21T11:54:34.504014500Z"
    }
   },
   "id": "a55b705e23c8120"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random forest tuning:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6252599474cf9d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T11:42:08.070906500Z",
     "start_time": "2025-04-21T10:53:38.919171500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_cols = X.select_dtypes(['number']).columns\n",
    "cat_cols = X.select_dtypes(['object']).columns\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('outlier', HandleOutliers(lower_quantile=0.3, upper_quantile=0.7)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.1)\n",
    "select_k = SelectKBest(score_func=mutual_info_classif, k=100)\n",
    "log_reg = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "rfe = RFE(estimator=log_reg, n_features_to_select=50)\n",
    "\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('variance_threshold', var_thresh),\n",
    "    ('select_k_best', select_k),\n",
    "    ('rfe', rfe),\n",
    "    ('classifier', RandomForestClassifier(random_state=22)),\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [10,20, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_pipeline,\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "print(\"RF Best Parameters:\", grid_search_rf.best_params_)\n",
    "print(\"Best roc_auc score:\", grid_search_rf.best_score_)"
   ],
   "id": "f5a7b5f8d992b186",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "RF Best Parameters: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 200}\n",
      "Best roc_auc score: 0.9632225384691863\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "LightGBM tuning:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c99c5118835b82a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:21:43.757672900Z",
     "start_time": "2025-04-21T16:27:23.939649900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_cols = X.select_dtypes(['number']).columns\n",
    "cat_cols = X.select_dtypes(['object']).columns\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('outlier', HandleOutliers(lower_quantile=0.3, upper_quantile=0.7)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.1)\n",
    "select_k = SelectKBest(score_func=mutual_info_classif, k=100)\n",
    "log_reg = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "rfe = RFE(estimator=log_reg, n_features_to_select=50)\n",
    "\n",
    "\n",
    "lgbm_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('variance_threshold', var_thresh),\n",
    "    ('select_k_best', select_k),\n",
    "    ('rfe', rfe),\n",
    "    ('classifier', LGBMClassifier(random_state=22)),\n",
    "])\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'classifier__n_estimators': [100, 500, 1000],\n",
    "    'classifier__max_depth': [-1, 10, 20],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.3],\n",
    "    'classifier__num_leaves': [31, 50, 100],\n",
    "    'classifier__min_child_samples': [10, 20, 50],\n",
    "    'classifier__subsample': [0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search_lgbm = GridSearchCV(\n",
    "    estimator=lgbm_pipeline,\n",
    "    param_grid=param_grid_lgbm,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "grid_search_lgbm.fit(X_train, y_train)\n",
    "print(\"RF Best Parameters:\", grid_search_lgbm.best_params_)\n",
    "print(\"Best roc_auc score:\", grid_search_lgbm.best_score_)"
   ],
   "id": "23e272f9509baa3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 972 candidates, totalling 2916 fits\n",
      "[LightGBM] [Info] Number of positive: 4615, number of negative: 10493\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 468\n",
      "[LightGBM] [Info] Number of data points in the train set: 15108, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.305467 -> initscore=-0.821397\n",
      "[LightGBM] [Info] Start training from score -0.821397\n",
      "RF Best Parameters: {'classifier__colsample_bytree': 0.8, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 10, 'classifier__min_child_samples': 50, 'classifier__n_estimators': 500, 'classifier__num_leaves': 31, 'classifier__subsample': 1.0}\n",
      "Best roc_auc score: 0.9665810217634306\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are going to be continuing with evaluating the models using the best hyperparameters we found in the notebook \"evaluating_comparing.ipynb\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e1045bbcee6fb37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7909b9b955d3c289"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
