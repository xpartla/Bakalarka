{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-25T13:47:53.845608700Z",
     "start_time": "2025-03-25T13:47:53.129694100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "pd.options.display.max_columns = None\n",
    "import joblib\n",
    "from itertools import chain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv', low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T13:47:56.151030400Z",
     "start_time": "2025-03-25T13:47:53.816359700Z"
    }
   },
   "id": "f396314cfb41a86b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial: 862\n",
      "remaining: 213\n",
      "dropped: 649\n"
     ]
    }
   ],
   "source": [
    "max_vals = df.select_dtypes(include='number').max()\n",
    "max_9 = max_vals[max_vals == 9].index.tolist()\n",
    "for col in max_9:\n",
    "    df.loc[df[col] == 9, col] = np.nan \n",
    "max_vals = df.select_dtypes(include='number').max()\n",
    "max_8 = max_vals[max_vals == 8].index.tolist()\n",
    "\n",
    "missing_subset = {'ALCFREQ', 'HATTMULT', 'STROKMUL', 'TIAMULT', 'ARTHTYPE', 'ARTHUPEX', 'ARTHLOEX', 'ARTHSPIN', 'ARTHUNK', 'CVDCOG', 'STROKCOG', 'CVDIMAG', 'CVDIMAG1', 'CVDIMAG2', 'CVDIMAG3', 'CVDIMAG4', 'PDNORMAL', 'SPEECH', 'FACEXP', 'TRESTRHD', 'TRESTLHD', 'TRESTRFT', 'TRESTLFT', 'TRACTRHD', 'TRACTLHD', 'RIGDNECK', 'RIGDUPRT', 'RIGDUPLF', 'RIGDLORT', 'RIGDLOLF', 'TAPSRT', 'TAPSLF', 'HANDMOVR', 'HANDMOVL', 'HANDALTR', 'HANDALTL', 'LEGRT', 'LEGLF', 'ARISING', 'POSTURE', 'GAIT', 'POSSTAB', 'BRADYKIN', 'RESTTRL', 'RESTTRR', 'SLOWINGL', 'SLOWINGR', 'RIGIDL', 'RIGIDR', 'BRADY', 'POSTINST', 'CORTDEF', 'SIVDFIND', 'CVDMOTL', 'CVDMOTR', 'CORTVISL', 'CORTVISR', 'SOMATL', 'SOMATR', 'EYEPSP', 'DYSPSP', 'AXIALPSP', 'GAITPSP', 'APRAXSP', 'APRAXL', 'APRAXR', 'CORTSENL', 'CORTSENR', 'ATAXL', 'ATAXR', 'ALIENLML', 'ALIENLMR', 'DYSTONL', 'DYSTONR', 'MYOCLLT', 'MYOCLRT', 'MOMOPARK', 'MOMOALS', 'AMNDEM', 'PCA', 'NAMNDEM', 'AMYLPET', 'AMYLCSF', 'FDGAD', 'HIPPATR', 'TAUPETAD', 'CSFTAU', 'FDGFTLD', 'TPETFTLD', 'MRFTLD', 'DATSCAN', 'IMAGLINF', 'IMAGLAC', 'IMAGMACH', 'IMAGMICH', 'IMAGMWMH', 'IMAGEWMH', 'CANCER', 'MYOINF', 'CONGHRT', 'AFIBRILL', 'HYPERT', 'ANGINA', 'HYPCHOL', 'VB12DEF', 'THYDIS', 'ARTH', 'ARTYPE', 'ARTUPEX', 'ARTLOEX', 'ARTSPIN', 'ARTUNKN', 'URINEINC', 'BOWLINC', 'SLEEPAP', 'REMDIS', 'HYPOSOM', 'SLEEPOTH', 'ANGIOCP', 'ANGIOPCI', 'PACEMAKE', 'HVALVE', 'ANTIENC'}\n",
    "cols_to_change = list(missing_subset.intersection(max_8))\n",
    "df[cols_to_change] = df[cols_to_change].replace(8, np.nan)\n",
    "max_vals = df.select_dtypes(include='number').max()\n",
    "max_8 = max_vals[max_vals == 8].index.tolist()\n",
    "\n",
    "df = df.drop(columns=['NPWBRF', 'NACCBRNN', 'NPGRCCA', 'NPGRLA', 'NPGRHA', 'NPGRSNH', 'NPGRLCH', 'NACCAVAS', 'NPTAN', 'NPABAN', 'NPASAN', 'NPTDPAN', 'NPTHAL', 'NACCBRAA', 'NACCNEUR', 'NPADNC', 'NACCDIFF', 'NACCAMY', 'NPINF', 'NACCINF', 'NPHEMO', 'NPHEMO1', 'NPHEMO2', 'NPHEMO3', 'NPOLD', 'NPOLD1', 'NPOLD2', 'NPOLD3', 'NPOLD4', 'NACCMICR', 'NPOLDD', 'NPOLDD1', 'NPOLDD2', 'NPOLDD3', 'NPOLDD4', 'NACCHEM', 'NACCARTE', 'NPWMR', 'NPPATH', 'NACCNEC', 'NPPATH2', 'NPPATH3', 'NPPATH4', 'NPPATH5', 'NPPATH6', 'NPPATH7', 'NPPATH8', 'NPPATH9', 'NPPATH10', 'NPPATH11', 'NACCLEWY', 'NPLBOD', 'NPNLOSS', 'NPHIPSCL', 'NPFTDTAU', 'NACCPICK', 'NPFTDT2', 'NACCCBD', 'NACCPROG', 'NPFTDT5', 'NPFTDT6', 'NPFTDT7', 'NPFTDT8', 'NPFTDT9', 'NPFTDT10', 'NPFTDTDP', 'NPALSMND', 'NPOFTD', 'NPOFTD1', 'NPOFTD2', 'NPOFTD3', 'NPOFTD4', 'NPOFTD5', 'NPTDPA', 'NPTDPB', 'NPTDPC', 'NPTDPD', 'NPTDPE', 'NPPDXA', 'NPPDXB', 'NACCPRIO', 'NPPDXD', 'NPPDXE', 'NPPDXF', 'NPPDXG', 'NPPDXH', 'NPPDXI', 'NPPDXJ', 'NPPDXK', 'NPPDXL', 'NPPDXM', 'NPPDXN', 'NPPDXP', 'NPPDXQ', 'NPARTAG', 'NPATGSEV', 'NPATGAMY', 'NPATGAM1', 'NPATGAM2', 'NPATGAM3', 'NPATGAM4', 'NPATGAM5', 'NPATGFRN', 'NPATGFR1', 'NPATGFR2', 'NPATGFR3', 'NPATGFR4'])\n",
    "\n",
    "initial = df.shape[1]\n",
    "threshold = 0.8 * len(df)\n",
    "df = df.dropna(thresh=threshold, axis=1)\n",
    "remaining = df.shape[1]\n",
    "dropped = initial - remaining\n",
    "\n",
    "print(f\"initial: {initial}\")\n",
    "print(f\"remaining: {remaining}\")\n",
    "print(f\"dropped: {dropped}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T13:47:57.434504Z",
     "start_time": "2025-03-25T13:47:56.152032300Z"
    }
   },
   "id": "f002baf63680c05d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "impairment_vars = ['BILLS', 'SHOPPING', 'STOVE', 'TRAVEL']\n",
    "\n",
    "functional_impairment = df[impairment_vars].sum(axis=1, skipna=True)\n",
    "\n",
    "df = pd.concat([df, functional_impairment.rename('FUNCTIONAL_IMPAIRMENT')], axis=1)\n",
    "df.drop(columns=impairment_vars, inplace=True)\n",
    "\n",
    "df = df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T13:47:57.558027300Z",
     "start_time": "2025-03-25T13:47:57.441506100Z"
    }
   },
   "id": "f38e10ce3d63b2a1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29673\n"
     ]
    }
   ],
   "source": [
    "print(df.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T13:47:57.573158300Z",
     "start_time": "2025-03-25T13:47:57.561029400Z"
    }
   },
   "id": "41e80eb248835ed8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df = df[df[\"OUTCOME_EVENTMCI\"] == False | (df[\"TIME\"] <= 4)]\n",
    "df[\"OUTCOME_WITHIN_4_YEARS\"] = df[\"OUTCOME_EVENTMCI\"] & (df[\"TIME\"] <= 4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T13:47:57.606249100Z",
     "start_time": "2025-03-25T13:47:57.575064Z"
    }
   },
   "id": "4dd05905330df585"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14737\n"
     ]
    }
   ],
   "source": [
    "print(df.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T13:47:57.616256700Z",
     "start_time": "2025-03-25T13:47:57.601359600Z"
    }
   },
   "id": "1123e75231006779"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "7 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1031, in fit_transform\n",
      "    return self._hstack(list(Xs), n_samples=n_samples)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1225, in _hstack\n",
      "    return np.hstack(Xs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\numpy\\_core\\shape_base.py\", line 358, in hstack\n",
      "    return _nx.concatenate(arrs, 1, dtype=dtype, casting=casting)\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 694. MiB for an array with shape (9432, 9639) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1031, in fit_transform\n",
      "    return self._hstack(list(Xs), n_samples=n_samples)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1225, in _hstack\n",
      "    return np.hstack(Xs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\numpy\\_core\\shape_base.py\", line 358, in hstack\n",
      "    return _nx.concatenate(arrs, 1, dtype=dtype, casting=casting)\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 693. MiB for an array with shape (9431, 9638) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\base.py\", line 921, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_variance_threshold.py\", line 114, in fit\n",
      "    self.variances_ = np.nanvar(X, axis=0)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py\", line 1839, in nanvar\n",
      "    arr, mask = _replace_nan(a, 0)\n",
      "  File \"C:\\Bakalarka\\venv\\lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py\", line 109, in _replace_nan\n",
      "    a = np.array(a, subok=True, copy=True)\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 694. MiB for an array with shape (9432, 9639) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Bakalarka\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.99297928        nan 0.99742804\n",
      "        nan 0.99730911 0.9974437  0.99744588 0.99746572 0.9974679\n",
      " 0.99743549 0.99741151 0.99741893 0.99741936 0.99741065 0.99741137\n",
      " 0.99741151 0.99741268]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Best Hyperparameters:  {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Best roc_auc score:  0.9974678974095825\n"
     ]
    }
   ],
   "source": [
    "print(df['TIME'], df['OUTCOME_WITHIN_4_YEARS'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T14:28:02.014612700Z",
     "start_time": "2025-03-25T14:24:43.916379300Z"
    }
   },
   "id": "6e081e8a562a0cb1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X = df.drop(columns=['OUTCOME_WITHIN_4_YEARS'])\n",
    "y = df['OUTCOME_WITHIN_4_YEARS']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22, stratify=y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T13:47:57.681551800Z",
     "start_time": "2025-03-25T13:47:57.633257900Z"
    }
   },
   "id": "fb648bacc3a7cee7"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class HandleOutliers(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower_quantile=0.3, upper_quantile=0.7):\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        self.quantile_bounds_ = {}\n",
    "        numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "        \n",
    "        for col in numeric_columns:\n",
    "            Q1 = X[col].quantile(self.lower_quantile)\n",
    "            Q2 = X[col].quantile(self.upper_quantile)\n",
    "            IQR = Q2 - Q1\n",
    "            self.quantile_bounds_[col] = {\n",
    "                'lower_bound': Q1 - 1.5 * IQR,\n",
    "                'upper_bound': Q2 + 1.5 * IQR\n",
    "            }\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "        for col in numeric_columns:\n",
    "            if col not in self.quantile_bounds_:\n",
    "                continue  \n",
    "            bounds = self.quantile_bounds_[col]\n",
    "            mean_value = X[col].mean()\n",
    "            \n",
    "            X[col] = np.where(X[col] < bounds['lower_bound'], mean_value, \n",
    "                              np.where(X[col] > bounds['upper_bound'], mean_value, X[col]))\n",
    "        return X.values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T13:47:57.704312100Z",
     "start_time": "2025-03-25T13:47:57.682552800Z"
    }
   },
   "id": "187b11c0f74215cf"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.9760793960471627, 0.9735413839891451, 'pipeline.pkl')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = X.select_dtypes(['number']).columns\n",
    "cat_cols = X.select_dtypes(['object']).columns\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('outlier', HandleOutliers(lower_quantile=0.3, upper_quantile=0.7)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_cols),\n",
    "    ('cat', cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.1)\n",
    "select_k = SelectKBest(score_func=f_classif, k=50)\n",
    "log_reg = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=20)\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('variance_threshold', var_thresh),\n",
    "    ('select_k_best', select_k),\n",
    "    ('rfe', rfe),\n",
    "    ('classifier', LogisticRegression(max_iter=200))\n",
    "])\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_score = full_pipeline.score(X_train, y_train)\n",
    "test_predictions = full_pipeline.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "train_score, test_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T14:10:09.959080100Z",
     "start_time": "2025-03-25T14:10:02.735940400Z"
    }
   },
   "id": "7bab6cb2c32e42de"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-25T13:48:26.994149700Z",
     "start_time": "2025-03-25T13:48:26.950437800Z"
    }
   },
   "id": "b714ea2cd43bfa59"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
